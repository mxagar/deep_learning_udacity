# Pytorch Guide

These are my personal notes taken while following the [Udacity Deep Learning Nanodegree](https://www.udacity.com/course/deep-learning-nanodegree--nd101).

The nanodegree is composed of six modules:

1. Introduction to Deep Learning
2. Neural Networks and Pytorch Guide
3. Convolutonal Neural Networks (CNN)
4. Recurrent Neural Networks (RNN)
5. Generative Adversarial Networks (GAN)
6. Deploying a Model

Each module has a folder with its respective notes. This folder is the one of the **second module** and it contains a Pytorch guide.

Additionally, note that I made many hand-written nortes, which I will scan and push to this repostory.

Here, I refence notebooks that are present in two repositories (both updated):

- [DL_PyTorch](https://github.com/mxagar/DL_PyTorch), referenced in the CVND
- [deep-learning-v2-pytorch](https://github.com/mxagar/deep-learning-v2-pytorch), the one used in the DLND

Additionally, in this particular folder, I also collect some examples and summaries made by myself.

## Overview of Contents

1. Introduction
2. Tensors: `Part 1 - Tensors in Pytorch.ipynb`
3. Neural Networks: `Part 2 - Tensors in Pytorch.ipynb`
4. Training Neural Networks: `Part 3 - Training Neural Networks.ipynb`
5. Fashion-MNIST Example: `Part 4 - Fashion-MNIST.ipynb`
6. Inference and Validation: `Part 5 - Inference and Validation.ipynb`
7. Saving and Loading Models: `Part 6 - Saving and Loading Models.ipynb`
8. Loading Image Data: `Part 7 - Loading Image Data.ipynb`
9. Transfer Learning: `Part 8 - Transfer Learning.ipynb`

## 1. Introduction

Primarily developed by Facebook AI Research (FAIR).  
Released in 2017.  
Open Source, BSD.  
Very intuitive: similar to Numpy and DL concepts integrate din a more natural way; more intuitive than TensorFlow or Keras.  
Caffe2 was integrated to PyTorch in 2018.  
Main intefarce: Python - it's very Pythonic; C++ interface is available too.  
Main class: Tensors = multidimensional arrays, similar to Numpy's, but they can be operated on CUDA GPUs.  
Automatic differentiation used (autodiff?): derivative used in backpropagation computed in feedforward pass.  

Very interesting Tutorial: [DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)

## 2. Tensors: `Part 1 - Tensors in Pytorch.ipynb`



## 3. Neural Networks: `Part 2 - Tensors in Pytorch.ipynb`



## 4. Training Neural Networks: `Part 3 - Training Neural Networks.ipynb`



## 5. Fashion-MNIST Example: `Part 4 - Fashion-MNIST.ipynb`



## 6. Inference and Validation: `Part 5 - Inference and Validation.ipynb`



## 7. Saving and Loading Models: `Part 6 - Saving and Loading Models.ipynb`



## 8. Loading Image Data: `Part 7 - Loading Image Data.ipynb`



## 9. Transfer Learning: `Part 8 - Transfer Learning.ipynb`



